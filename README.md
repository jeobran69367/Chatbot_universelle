# ğŸ¤– Chatbot Web Scraper Intelligent

Un chatbot intelligent capable de scraper des sites web, vectoriser le contenu et rÃ©pondre aux questions en utilisant OpenAI et des techniques de RAG (Retrieval Augmented Generation).

## âœ¨ FonctionnalitÃ©s

- ğŸ•·ï¸ **Web Scraping AvancÃ©**: Scrape automatiquement un site web et toutes ses pages liÃ©es
- ğŸ§  **Intelligence Artificielle**: Utilise OpenAI GPT pour gÃ©nÃ©rer des rÃ©ponses contextuelles
- ğŸ“Š **Base de DonnÃ©es Vectorielle**: Stocke et recherche efficacement dans le contenu scrapÃ©
- ğŸ¨ **Interface Intuitive**: Interface web moderne avec Streamlit
- ğŸ” **Recherche SÃ©mantique**: Trouve le contenu pertinent pour chaque question
- ğŸ’¬ **Conversation Contextuelle**: Maintient l'historique des conversations

## ğŸ› ï¸ Technologies UtilisÃ©es

- **Frontend**: Streamlit
- **AI/ML**: OpenAI GPT, Sentence Transformers
- **Web Scraping**: BeautifulSoup, Selenium, Requests
- **Base de DonnÃ©es Vectorielle**: ChromaDB ou FAISS
- **Traitement de Texte**: NLTK, spaCy, LangChain
- **Langages**: Python 3.8+

## ğŸ“¦ Installation

### 1. Cloner le projet
```bash
git clone <votre-repo>
cd Model
```

### 2. CrÃ©er un environnement virtuel
```bash
python -m venv venv
source venv/bin/activate  # Sur macOS/Linux
# ou
venv\Scripts\activate  # Sur Windows
```

### 3. Installer les dÃ©pendances
```bash
pip install -r requirements.txt
```

### 4. Configuration des variables d'environnement
Copiez le fichier `.env` et ajustez les valeurs :
```bash
cp .env.example .env
```

Modifiez le fichier `.env` avec vos clÃ©s API :
```env
OPENAI_API_KEY=your_openai_api_key_here
```

### 5. Lancer l'application
```bash
streamlit run app.py
```

## ğŸš€ Utilisation

### Interface Web

1. **Scraping d'un Site Web**:
   - Entrez l'URL du site dans la sidebar
   - Configurez le nombre maximum de pages
   - Choisissez d'utiliser Selenium si nÃ©cessaire
   - Cliquez sur "Lancer le Scraping"

2. **Poser des Questions**:
   - Tapez votre question dans la zone de texte
   - Le chatbot utilisera le contenu scrapÃ© pour rÃ©pondre
   - Les sources utilisÃ©es sont affichÃ©es dans la sidebar

3. **Gestion des DonnÃ©es**:
   - Consultez l'onglet "DonnÃ©es" pour voir les informations scrapÃ©es
   - Chargez des donnÃ©es existantes si disponibles

### Utilisation Programmatique

```python
from src.web_scraper import WebScraper
from src.vector_database import VectorDatabase
from src.chatbot import ChatBot

# 1. Scraper un site web
scraper = WebScraper()
pages = scraper.scrape_website("https://example.com", max_pages=20)

# 2. CrÃ©er la base de donnÃ©es vectorielle
vector_db = VectorDatabase("chroma")
vector_db.add_documents_from_scraped_data(pages)

# 3. Initialiser le chatbot
chatbot = ChatBot()

# 4. Poser une question
search_results = vector_db.search_similar("ma question", n_results=5)
response = chatbot.generate_response("ma question", search_results)
print(response["response"])
```

## ğŸ“ Structure du Projet

```
Model/
â”œâ”€â”€ app.py                 # Interface Streamlit principale
â”œâ”€â”€ requirements.txt       # DÃ©pendances Python
â”œâ”€â”€ .env                  # Variables d'environnement
â”œâ”€â”€ README.md             # Documentation
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py       # Configuration de l'application
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ web_scraper.py    # Module de scraping web
â”‚   â”œâ”€â”€ vector_database.py # Base de donnÃ©es vectorielle
â”‚   â””â”€â”€ chatbot.py        # IntÃ©gration OpenAI
â””â”€â”€ data/                 # DonnÃ©es scrapÃ©es et modÃ¨les
    â”œâ”€â”€ scraped/          # DonnÃ©es JSON brutes
    â”œâ”€â”€ embeddings/       # Base de donnÃ©es vectorielle
    â””â”€â”€ models/           # ModÃ¨les tÃ©lÃ©chargÃ©s
```

## âš™ï¸ Configuration AvancÃ©e

### ParamÃ¨tres de Scraping

Dans `config/settings.py` :

```python
MAX_PAGES_PER_SITE = 100    # Limite de pages par site
REQUEST_DELAY = 1           # DÃ©lai entre les requÃªtes (secondes)
MAX_RETRIES = 3             # Nombre de tentatives
TIMEOUT = 30                # Timeout des requÃªtes
```

### ParamÃ¨tres de Vectorisation

```python
CHUNK_SIZE = 1000           # Taille des chunks de texte
CHUNK_OVERLAP = 200         # Chevauchement entre chunks
SIMILARITY_THRESHOLD = 0.7  # Seuil de similaritÃ©
```

### ModÃ¨les OpenAI

```python
OPENAI_MODEL = "gpt-3.5-turbo"  # ou "gpt-4"
EMBEDDING_MODEL = "text-embedding-ada-002"
```

## ğŸ”§ Personnalisation

### Ajouter de Nouvelles Sources de DonnÃ©es

```python
# Dans web_scraper.py
def scrape_api_data(api_url):
    # ImplÃ©mentez votre logique de scraping d'API
    pass
```

### Modifier le Prompt SystÃ¨me

```python
# Dans chatbot.py
chatbot = ChatBot()
chatbot.set_system_prompt("Votre nouveau prompt systÃ¨me...")
```

### Changer de Base de DonnÃ©es Vectorielle

```python
# Utiliser FAISS au lieu de ChromaDB
vector_db = VectorDatabase("faiss")
```

## ğŸ› DÃ©pannage

### Erreurs Communes

1. **Erreur d'API OpenAI** : VÃ©rifiez votre clÃ© API dans le fichier `.env`
2. **Erreur de Selenium** : Installez ChromeDriver ou utilisez `use_selenium=False`
3. **ProblÃ¨mes de mÃ©moire** : RÃ©duisez `MAX_PAGES_PER_SITE` ou `CHUNK_SIZE`

### Logs de Debug

Pour activer les logs dÃ©taillÃ©s :

```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

## ğŸ“Š MÃ©triques et Performance

### Optimisations RecommandÃ©es

- Utilisez FAISS pour de gros volumes de donnÃ©es
- Ajustez `CHUNK_SIZE` selon votre contenu
- Utilisez un cache Redis pour les embeddings frÃ©quents
- ImplÃ©mentez une pagination pour l'interface web

### Limites Actuelles

- Maximum 100 pages par site (configurable)
- Token limit OpenAI (4K pour GPT-3.5-turbo)
- Pas de mise Ã  jour automatique du contenu

## ğŸ¤ Contribution

1. Fork le projet
2. CrÃ©ez votre branche (`git checkout -b feature/AmazingFeature`)
3. Committez vos changements (`git commit -m 'Add some AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrez une Pull Request

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.

## ğŸ™ Remerciements

- OpenAI pour les modÃ¨les GPT et les embeddings
- L'Ã©quipe Streamlit pour l'interface utilisateur
- La communautÃ© ChromaDB pour la base de donnÃ©es vectorielle
- Tous les contributeurs des librairies open-source utilisÃ©es

## ğŸ“ Support

Pour des questions ou du support :
- Ouvrez une issue sur GitHub
- Consultez la documentation des modules individuels
- VÃ©rifiez les logs d'application

---

**DÃ©veloppÃ© avec â¤ï¸ pour l'intelligence artificielle et la recherche sÃ©mantique.**
