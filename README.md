# ğŸ¤– Chatbot Web Scraper Intelligent

Un chatbot intelligent capable de scraper des sites web, vectoriser le contenu et rÃ©pondre aux questions en utilisant **Ollama** (LLaMA, Mistral, etc.) et des techniques de RAG (Retrieval Augmented Generation) - **100% local et privÃ©**.

## ğŸš€ **DÃ‰PLOIEMENT PROFESSIONNEL DOCKER + AZURE** 

Ce projet est maintenant Ã©quipÃ© d'une **infrastructure complÃ¨te de dÃ©ploiement** :
- ğŸ³ **Docker & Docker Compose** pour le dÃ©veloppement local
- â˜ï¸ **Azure Container Apps** pour la production 
- ğŸ”„ **CI/CD Pipeline GitHub Actions** 
- ğŸ“Š **Monitoring intÃ©grÃ©** (Prometheus, Grafana, Application Insights)
- ğŸ›¡ï¸ **SÃ©curitÃ© et bonnes pratiques**

## âœ¨ FonctionnalitÃ©s

- ğŸ•·ï¸ **Web Scraping AvancÃ©**: Scrape automatiquement un site web et toutes ses pages liÃ©es
- ğŸ§  **Intelligence Artificielle Locale**: Utilise Ollama avec LLaMA 3.1, Mistral ou d'autres modÃ¨les open-source
- ğŸ“Š **Base de DonnÃ©es Vectorielle**: Stocke et recherche efficacement dans le contenu scrapÃ©
- ğŸ¨ **Interface Intuitive**: Interface web moderne avec Streamlit + API Flask
- ğŸ” **Recherche SÃ©mantique**: Trouve le contenu pertinent pour chaque question
- ğŸ’¬ **Conversation Contextuelle**: Maintient l'historique des conversations
- ğŸ”’ **100% PrivÃ©**: Toutes les donnÃ©es restent en local, aucune API externe requise
- ğŸ­ **Prompts Personnalisables**: Styles de rÃ©ponse adaptables (dÃ©faut, expert, casual)
- ğŸ”„ **Cache Redis** : Performance optimisÃ©e avec cache distribuÃ©
- ğŸ“ˆ **Monitoring complet** : MÃ©triques, logs centralisÃ©s, alertes

## ğŸ› ï¸ Technologies UtilisÃ©es

### Stack Application
- **Frontend**: Streamlit + API Flask
- **AI/ML**: Ollama (LLaMA, Mistral, etc.), Sentence Transformers
- **Web Scraping**: BeautifulSoup, Selenium, Requests, Scrapy
- **Base de DonnÃ©es Vectorielle**: ChromaDB ou FAISS
- **Cache**: Redis pour sessions et performance
- **Traitement de Texte**: NLTK, spaCy, LangChain
- **Langages**: Python 3.11+

### Stack Infrastructure
- **ğŸ³ Containerisation**: Docker, Docker Compose
- **â˜ï¸ Cloud**: Azure Container Apps, Azure Storage, Redis Cache
- **ğŸ”„ CI/CD**: GitHub Actions, Azure DevOps
- **ğŸ“Š Monitoring**: Application Insights, Prometheus, Grafana
- **ğŸ›¡ï¸ SÃ©curitÃ©**: Managed Identity, Key Vault, HTTPS/TLS
- **ğŸ—ï¸ IaC**: Azure Bicep, Azure Developer CLI (azd)

## ï¿½ DÃ©marrage Rapide

### âš¡ Installation & DÃ©ploiement Ultra-Rapide

```bash
# 1. Cloner le projet
git clone <votre-repo>
cd Model

# 2. Configuration initiale complÃ¨te
make setup

# 3. DÃ©ploiement local avec Docker
make up

# 4. VÃ©rifier que tout fonctionne
make health
```

**ğŸŒ Application disponible sur http://localhost**

---

## ï¿½ğŸ“¦ Installation DÃ©taillÃ©e

### ğŸ³ Option A : DÃ©ploiement Docker (RecommandÃ©)

```bash
# Configuration et dÃ©ploiement en une commande
make setup && make up

# Avec monitoring (Prometheus + Grafana)
make deploy-local-monitoring

# AccÃ¨s aux services
# - Application: http://localhost
# - API: http://localhost/api
# - Grafana: http://localhost:3000 (admin/admin123)
# - Prometheus: http://localhost:9090
```

### â˜ï¸ Option B : DÃ©ploiement Azure

```bash
# PrÃ©requis: Azure CLI + azd installÃ©s
az login

# DÃ©ploiement complet sur Azure
make deploy-azure

# URL gÃ©nÃ©rÃ©e automatiquement: https://votre-app.azurecontainerapps.io
```

### ğŸ› ï¸ Option C : Installation Manuelle

### 1. Cloner le projet
```bash
git clone <votre-repo>
cd Model
```

### 2. CrÃ©er un environnement virtuel
```bash
python -m venv .venv
source .venv/bin/activate  # Sur macOS/Linux
# ou
.venv\Scripts\activate  # Sur Windows
```

### 3. Installer les dÃ©pendances
```bash
pip install -r requirements.txt
```

### 4. Installer et configurer Ollama

**Sur macOS:**
```bash
# Installer Ollama
brew install ollama

# Ou tÃ©lÃ©charger depuis https://ollama.ai/download
curl -fsSL https://ollama.ai/install.sh | sh
```

**Sur Linux:**
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

**Sur Windows:**
- TÃ©lÃ©chargez l'installateur depuis [https://ollama.ai/download](https://ollama.ai/download)
- ExÃ©cutez l'installateur et suivez les instructions

### 5. DÃ©marrer Ollama et tÃ©lÃ©charger un modÃ¨le
```bash
# DÃ©marrer le service Ollama (si pas auto-dÃ©marrÃ©)
ollama serve

# Dans un nouveau terminal, tÃ©lÃ©charger le modÃ¨le LLaMA 3.1
ollama pull llama3.1:latest

# Optionnel: TÃ©lÃ©charger des modÃ¨les plus lÃ©gers
ollama pull qwen2:0.5b    # ModÃ¨le trÃ¨s lÃ©ger (500MB)
ollama pull mistral:7b    # ModÃ¨le Mistral (4.1GB)

# VÃ©rifier les modÃ¨les installÃ©s
ollama list
```

### 6. Configuration des variables d'environnement
CrÃ©ez un fichier `.env` Ã  la racine du projet :
```bash
cp .env.example .env
```

Modifiez le fichier `.env` avec vos configurations :
```env
# Configuration Ollama
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.1:latest

# Configuration Streamlit (optionnel)
STREAMLIT_THEME_BASE=light
STREAMLIT_THEME_PRIMARY_COLOR=#FF6B6B
STREAMLIT_THEME_BACKGROUND_COLOR=#FFFFFF
```

### 7. Lancer l'application

**ğŸ” VÃ©rification rapide avant de commencer :**
```bash
# VÃ©rifier qu'Ollama fonctionne
ollama list

# Tester un modÃ¨le
ollama run llama3.1:latest "Bonjour, comment Ã§a va ?"

# VÃ©rifier l'environnement Python
source .venv/bin/activate
python -c "import streamlit, chromadb, sentence_transformers; print('âœ… Tous les modules OK')"
```

**Option 1 : Avec l'environnement virtuel activÃ©**
```bash
source .venv/bin/activate  # Sur macOS/Linux
# ou
.venv\Scripts\activate  # Sur Windows
streamlit run app.py
```

**Option 2 : Directement avec le chemin complet**
```bash
./.venv/bin/streamlit run app.py  # Sur macOS/Linux
# ou
.venv\Scripts\streamlit run app.py  # Sur Windows
```

**Option 3 : Script de dÃ©marrage automatique**
```bash
chmod +x start_chatbot.sh
./start_chatbot.sh
```

**ğŸš€ AccÃ¨s Ã  l'application :**
- Interface web : http://localhost:8501
- L'application se lance automatiquement dans votre navigateur

## ğŸš€ Utilisation

### Interface Web

1. **Scraping d'un Site Web**:
   - Entrez l'URL du site dans la sidebar
   - Configurez le nombre maximum de pages
   - Choisissez d'utiliser Selenium si nÃ©cessaire
   - Cliquez sur "Lancer le Scraping"

2. **Poser des Questions**:
   - Tapez votre question dans la zone de texte
   - Le chatbot utilisera le contenu scrapÃ© pour rÃ©pondre
   - Les sources utilisÃ©es sont affichÃ©es dans la sidebar

3. **Gestion des DonnÃ©es**:
   - Consultez l'onglet "DonnÃ©es" pour voir les informations scrapÃ©es
   - Chargez des donnÃ©es existantes si disponibles

### Utilisation Programmatique

```python
from src.web_scraper import WebScraper
from src.vector_database import VectorDatabase
from src.chatbot import ChatBot

# 1. Scraper un site web
scraper = WebScraper()
pages = scraper.scrape_website("https://example.com", max_pages=20)

# 2. CrÃ©er la base de donnÃ©es vectorielle
vector_db = VectorDatabase("chroma")
vector_db.add_documents_from_scraped_data(pages)

# 3. Initialiser le chatbot
chatbot = ChatBot()

# 4. Poser une question
search_results = vector_db.search_similar("ma question", n_results=5)
response = chatbot.generate_response("ma question", search_results)
print(response["response"])
```

## ğŸ“ Structure du Projet

```
Model/
â”œâ”€â”€ app.py                 # Interface Streamlit principale
â”œâ”€â”€ requirements.txt       # DÃ©pendances Python
â”œâ”€â”€ .env                  # Variables d'environnement
â”œâ”€â”€ README.md             # Documentation
â”œâ”€â”€ start_chatbot.sh      # Script de dÃ©marrage automatique
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ settings.py       # Configuration de l'application
â”‚   â””â”€â”€ prompts.py        # Configuration des prompts systÃ¨me
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ web_scraper.py    # Module de scraping web
â”‚   â”œâ”€â”€ vector_database.py # Base de donnÃ©es vectorielle
â”‚   â”œâ”€â”€ chatbot.py        # IntÃ©gration Ollama
â”‚   â””â”€â”€ robust_vector_db.py # Solution robuste ChromaDB
â””â”€â”€ data/                 # DonnÃ©es scrapÃ©es et modÃ¨les
    â”œâ”€â”€ scraped/          # DonnÃ©es JSON brutes
    â”œâ”€â”€ embeddings/       # Base de donnÃ©es vectorielle
    â””â”€â”€ models/           # ModÃ¨les tÃ©lÃ©chargÃ©s
```

## âš™ï¸ Configuration AvancÃ©e

### ParamÃ¨tres de Scraping

Dans `config/settings.py` :

```python
MAX_PAGES_PER_SITE = 100    # Limite de pages par site
REQUEST_DELAY = 1           # DÃ©lai entre les requÃªtes (secondes)
MAX_RETRIES = 3             # Nombre de tentatives
TIMEOUT = 30                # Timeout des requÃªtes
```

### ParamÃ¨tres de Vectorisation

```python
CHUNK_SIZE = 1000           # Taille des chunks de texte
CHUNK_OVERLAP = 200         # Chevauchement entre chunks
SIMILARITY_THRESHOLD = 0.7  # Seuil de similaritÃ©
```

### ModÃ¨les Ollama

```python
# Configuration dans .env ou directement
OLLAMA_MODEL = "llama3.1:latest"  # ModÃ¨le par dÃ©faut
OLLAMA_MODEL = "mistral:7b"       # ModÃ¨le Mistral
OLLAMA_MODEL = "qwen2:0.5b"       # ModÃ¨le lÃ©ger pour tests
```

**ModÃ¨les recommandÃ©s :**
- `llama3.1:latest` - Excellent Ã©quilibre performance/qualitÃ© (4.6GB)
- `mistral:7b` - TrÃ¨s bon pour le franÃ§ais (4.1GB)
- `qwen2:0.5b` - Ultra-lÃ©ger pour dÃ©veloppement (500MB)
- `codellama:latest` - SpÃ©cialisÃ© en programmation (3.8GB)

## ğŸ”§ Personnalisation

### Ajouter de Nouvelles Sources de DonnÃ©es

```python
# Dans web_scraper.py
def scrape_api_data(api_url):
    # ImplÃ©mentez votre logique de scraping d'API
    pass
```

### Modifier le Prompt SystÃ¨me

**Option 1: Via l'interface Streamlit**
- Utilisez le sÃ©lecteur "Style de rÃ©ponse" dans la sidebar
- Styles disponibles: `default`, `expert`, `casual`

**Option 2: Par programmation**
```python
# Dans chatbot.py
chatbot = ChatBot(prompt_style="expert")  # Style au dÃ©marrage

# Ou changer dynamiquement
chatbot.set_system_prompt(style="casual")
chatbot.set_system_prompt("Votre prompt personnalisÃ©...")
```

**Option 3: Personnalisation avancÃ©e**
Modifiez le fichier `config/prompts.py` pour ajouter vos propres styles de prompts.

### Changer de Base de DonnÃ©es Vectorielle

```python
# Utiliser FAISS au lieu de ChromaDB
vector_db = VectorDatabase("faiss")
```

## ğŸ› DÃ©pannage

### Erreurs Communes

1. **Erreur de connexion Ollama** : 
   - VÃ©rifiez qu'Ollama est dÃ©marrÃ© : `ollama serve`
   - VÃ©rifiez le modÃ¨le : `ollama list`
   - RedÃ©marrez Ollama si nÃ©cessaire

2. **ModÃ¨le non trouvÃ©** :
   ```bash
   ollama pull llama3.1:latest
   ```

3. **Erreur de Selenium** : 
   - Installez ChromeDriver ou utilisez `use_selenium=False`
   - Sur macOS : `brew install chromedriver`

4. **ProblÃ¨mes de mÃ©moire** : 
   - RÃ©duisez `MAX_PAGES_PER_SITE` ou `CHUNK_SIZE`
   - Utilisez un modÃ¨le plus lÃ©ger comme `qwen2:0.5b`

5. **Port 11434 occupÃ©** :
   ```bash
   # ArrÃªter Ollama
   killall ollama
   # RedÃ©marrer
   ollama serve
   ```

### Logs de Debug

Pour activer les logs dÃ©taillÃ©s :

```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

## ğŸ“Š MÃ©triques et Performance

### Optimisations RecommandÃ©es

- Utilisez FAISS pour de gros volumes de donnÃ©es
- Ajustez `CHUNK_SIZE` selon votre contenu
- Utilisez un cache Redis pour les embeddings frÃ©quents
- ImplÃ©mentez une pagination pour l'interface web

### Limites Actuelles

- Maximum 100 pages par site (configurable)
- Limite de contexte Ollama (variable selon le modÃ¨le)
- Pas de mise Ã  jour automatique du contenu
- NÃ©cessite Ollama en local (peut Ãªtre dÃ©ployÃ© en remote)

## ğŸ¤ Contribution

1. Fork le projet
2. CrÃ©ez votre branche (`git checkout -b feature/AmazingFeature`)
3. Committez vos changements (`git commit -m 'Add some AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrez une Pull Request

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.

## ğŸ™ Remerciements

- **Ollama** pour l'infrastructure d'IA locale
- **Meta AI** pour les modÃ¨les LLaMA
- **Mistral AI** pour les modÃ¨les Mistral
- L'Ã©quipe **Streamlit** pour l'interface utilisateur
- La communautÃ© **ChromaDB** pour la base de donnÃ©es vectorielle
- Tous les contributeurs des librairies open-source utilisÃ©es

## ï¿½ Commandes Make Utiles

| Commande | Description |
|----------|-------------|
| `make help` | Afficher toutes les commandes disponibles |
| `make setup` | Configuration initiale complÃ¨te |
| `make up` | DÃ©marrer l'application localement |
| `make deploy-azure` | DÃ©ployer sur Azure |
| `make logs` | Voir les logs en temps rÃ©el |
| `make health` | VÃ©rifier l'Ã©tat de l'application |
| `make clean` | Nettoyer les fichiers temporaires |
| `make backup` | Sauvegarder les donnÃ©es |

## ğŸ“‹ Architecture de Production

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   GitHub Repo   â”‚
                    â”‚   (CI/CD Push)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ GitHub Actions  â”‚
                    â”‚ (Build & Deploy)â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚            Azure Container Apps           â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
        â”‚  â”‚   Streamlit     â”‚ â”‚    Ollama       â”‚ â”‚
        â”‚  â”‚   (Port 8501)   â”‚ â”‚  (Port 11434)   â”‚ â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
        â”‚  â”‚   Flask API     â”‚ â”‚   ChromaDB      â”‚ â”‚
        â”‚  â”‚   (Port 5001)   â”‚ â”‚  (Embeddings)   â”‚ â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
        â”‚  â”‚  Azure Storage  â”‚â”‚â”‚   Redis Cache   â”‚  â”‚
        â”‚  â”‚  (Persistent)   â”‚â”‚â”‚   (Sessions)    â”‚  â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
        â”‚  â”‚App Insights     â”‚â”‚â”‚  Log Analytics  â”‚  â”‚
        â”‚  â”‚(Monitoring)     â”‚â”‚â”‚    (Logs)       â”‚  â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”— Liens Utiles

- ğŸ“– **Documentation complÃ¨te** : [DEPLOYMENT.md](./DEPLOYMENT.md)
- ğŸ³ **Guide Docker** : Voir `docker-compose.yml`
- â˜ï¸ **Configuration Azure** : Voir `infra/main.bicep`
- ğŸ”„ **Pipeline CI/CD** : Voir `.github/workflows/`
- ğŸ“Š **Monitoring** : Voir `monitoring/prometheus.yml`

## ï¿½ğŸ“ Support

Pour des questions ou du support :
- ğŸ“‹ **Ouvrez une issue** sur GitHub
- ğŸ“– **Consultez** `DEPLOYMENT.md` pour les dÃ©tails de dÃ©ploiement
- ğŸ” **VÃ©rifiez les logs** : `make logs` (local) ou `make logs-azure` (Azure)
- ğŸ¥ **Status santÃ©** : `make health`

## ğŸ†• NouveautÃ©s v2.0

- âœ… **DÃ©ploiement Docker complet** avec orchestration
- âœ… **Infrastructure Azure** automatisÃ©e avec Bicep
- âœ… **CI/CD Pipeline** GitHub Actions
- âœ… **Monitoring intÃ©grÃ©** (Prometheus, Grafana, App Insights)
- âœ… **Cache Redis** pour amÃ©liorer les performances
- âœ… **SÃ©curitÃ© renforcÃ©e** (Managed Identity, HTTPS)
- âœ… **Scripts automatisÃ©s** pour simplifier le dÃ©ploiement
- âœ… **Documentation complÃ¨te** et guides d'utilisation

---

**DÃ©veloppÃ© avec â¤ï¸ pour l'intelligence artificielle, la recherche sÃ©mantique et l'infrastructure moderne.**

ğŸš€ **PrÃªt pour la production - Scalable - SÃ©curisÃ© - Monitored**
